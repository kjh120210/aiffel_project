{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "950efea4",
   "metadata": {},
   "source": [
    "# RockScisserPaper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab7c414",
   "metadata": {},
   "source": [
    "## 루브릭 평가\n",
    "\n",
    "1. 이미지 분류기 모델이 성공적으로 만들어졌는가?\n",
    "    - 트레이닝이 정상적으로 수행되었음\n",
    "2. 오버피팅을 극복하기 위한 적절한 시도가 있었는가?\n",
    "    - 데이터셋의 다양성, 정규화 등의 시도가 적절하였음\n",
    "3. 분류모델의 test accuracy가 기준 이상 높게 나왔는가?\n",
    "    - 60% 이상 도달하였음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74221f43",
   "metadata": {},
   "source": [
    "## 목차\n",
    "1. 라이브러리 선언\n",
    "2. 이미지 크기를 변경하는 함수 작성\n",
    "3. 학습데이터 만들고 reshape하기\n",
    "4. 테스트 데이터 만들고 reshape 하기\n",
    "5. 인공지능 모델 만들기\n",
    "6. 학습하고 결과 확인하기\n",
    "7. 훈련 accuracy, loss 그래프로 그려보기\n",
    "8. 회고 및 기록\n",
    "    - 프로젝트를 하면서 느낀점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf5adcf",
   "metadata": {},
   "source": [
    "## 라이브러리 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66641d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 라이브러리\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f03bb7b",
   "metadata": {},
   "source": [
    "## 이미지 크기를 변경하는 합수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29093ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기를 28X28로 변경하는 함수\n",
    "def resize_images(img_path):\n",
    "    # 디렉토리에서 jpg 파일 가져오기\n",
    "    images=glob.glob(img_path + \"/*.jpg\")\n",
    "    \n",
    "    print(len(images), \"images to be resized.\")\n",
    "    \n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \"images resized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933eb1d5",
   "metadata": {},
   "source": [
    "## 학습데이터 만들고 reshape하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81f8a96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3309 입니다.\n",
      "x_train shape: (3309, 28, 28, 3)\n",
      "y_train shape: (3309,)\n",
      "Before Reshape - x_train_norm shape: (3309, 28, 28, 3)\n",
      "After Reshape - x_train_reshaped shape: (3309, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "#이미지 크기 변경\n",
    "image_dir_path = os.getenv(\"HOME\") +\"/aiffel/aiffel_project/exploration_1/data/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") +\"/aiffel/aiffel_project/exploration_1/data/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") +\"/aiffel/aiffel_project/exploration_1/data/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "#훈련 데이터 함수\n",
    "def load_data(img_path, number_of_data=3309):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/aiffel_project/exploration_1/data\"\n",
    "\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "# 훈련 데이터 모양 찍기\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "\n",
    "# 훈련 데이터 reshape 하기\n",
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3)\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7523366",
   "metadata": {},
   "source": [
    "## 테스트 데이터 만들고 reshape 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a7ccba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images to be resized.\n",
      "100 images resized.\n",
      "100 images to be resized.\n",
      "100 images resized.\n",
      "100 images to be resized.\n",
      "100 images resized.\n",
      "테스트 데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n",
      "Before Reshape - x_test_norm shape: (300, 28, 28, 3)\n",
      "After Reshape - x_test_reshaped shape: (300, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 이미지 크기 변경\n",
    "test_image_dir_path = os.getenv(\"HOME\") +\"/aiffel/aiffel_project/exploration_1/test/scissor\"\n",
    "resize_images(test_image_dir_path)\n",
    "test_image_dir_path = os.getenv(\"HOME\") +\"/aiffel/aiffel_project/exploration_1/test/rock\"\n",
    "resize_images(test_image_dir_path)\n",
    "test_image_dir_path = os.getenv(\"HOME\") +\"/aiffel/aiffel_project/exploration_1/test/paper\"\n",
    "resize_images(test_image_dir_path)\n",
    "\n",
    "# 테스트 데이터 함수\n",
    "def load_data_test(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트 데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "test_image_dir_path = os.getenv(\"HOME\") + \"/aiffel/aiffel_project/exploration_1/test\"\n",
    "\n",
    "(x_test, y_test)=load_data_test(test_image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "# 데스트 데이터 모양 찍기\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n",
    "# 테스트 데이터 reshape 하기\n",
    "print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)\n",
    "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a1540c",
   "metadata": {},
   "source": [
    "### 이미지 확인 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b9ab794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train_norm[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72aead8",
   "metadata": {},
   "source": [
    "## 인공지능 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7451a778",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 122,506\n",
      "Trainable params: 122,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "#n_channel_3=64\n",
    "# n_dense_1=64\n",
    "n_dense=64\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3))) \n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "# 성능 향성을 위행 층 증가했지만 성능이 올라가지는 않음\n",
    "# model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "# model.add(keras.layers.MaxPooling2D((2,2))) \n",
    "# model.add(keras.layers.Flatten())\n",
    "# model.add(keras.layers.Dense(n_dense_1, activation='relu')) \n",
    "# model.add(keras.layers.Dropout(0.3)) 과적합을 막기위해서 사용\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "# model.add(keras.layers.Dropout(0.3))\n",
    "# 여기서 10이 아닌 3이 들어가야 한다고 생각하는데 10이 결과가 잘나와서 일단은 10으로 작성하였다.\n",
    "model.add(keras.layers.Dense(10, activation='softmax')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ed904",
   "metadata": {},
   "source": [
    "## 학습하고 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fc11ad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "104/104 [==============================] - 1s 3ms/step - loss: 1.1491 - accuracy: 0.4095\n",
      "Epoch 2/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.8601 - accuracy: 0.6111\n",
      "Epoch 3/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.7600\n",
      "Epoch 4/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.8256\n",
      "Epoch 5/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8761\n",
      "Epoch 6/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8957\n",
      "Epoch 7/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.2365 - accuracy: 0.9248\n",
      "Epoch 8/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.1868 - accuracy: 0.9468\n",
      "Epoch 9/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9607\n",
      "Epoch 10/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.1144 - accuracy: 0.9725\n",
      "Epoch 11/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 0.9776\n",
      "Epoch 12/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9864\n",
      "Epoch 13/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9927\n",
      "Epoch 14/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9937\n",
      "Epoch 15/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9840\n",
      "Epoch 16/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9979\n",
      "Epoch 17/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9961\n",
      "Epoch 18/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9991\n",
      "Epoch 19/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9985\n",
      "Epoch 20/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9949\n",
      "테스트 결과\n",
      "10/10 - 0s - loss: 1.1728 - accuracy: 0.6567\n",
      "test_loss: 1.1727834939956665 \n",
      "test_accuracy: 0.6566666960716248\n"
     ]
    }
   ],
   "source": [
    "# compile() 모델을 기계가 이해할 수 있도록 컴파일 합니다. 손실 함수와 옵티마이저, 메트릭 함수를 선택합니다.\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "# 모델 학습\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)\n",
    "\n",
    "print('테스트 결과')\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f95ebff",
   "metadata": {},
   "source": [
    "## 훈련 accuracy, loss 그래프로 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed877b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x축을 epoch, y축을 accuracy 또는 loss 로 나타내는 코드\n",
    "# 다른 파일에서 훈련하고 테스트할 때 사용하여 추가로 작성\n",
    "plt.plot(results.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(results.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e2ea78",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "### 사용한 데이터\n",
    "훈련 데이터 1103 * 3개  \n",
    "테스트 데이터 100 * 3개\n",
    "### 기록\n",
    "- 처음 정규화를 하지 않고 돌렸을때 test_accuracy가 0.03 test_loss가 10이상이 나왔다가 정규화를 하고 난 후에는 test_accuracy가 30퍼에 lose가 2점때가 나왔다. \n",
    "\n",
    "- 3번째 시도 : 층을 증가 시켜 보았다. \n",
    "        - 추가 했던 코드\n",
    "            - 결과 : test_accuracy: 0.47333332896232605, test_loss: 1.7697465419769287 \n",
    "            - 층을 늘리고 대략 17퍼 이상 올라가고 loss도 줄어들었다.\n",
    "```python\n",
    "n_channel_3=64\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "```\n",
    "- 4번째 시도 : epoch을 20으로 증가 시켜 보았다.\n",
    "        - 결과 test_accuracy : 0.5133333206176758, test_loss: 2.3954508304595947 \n",
    "        - accuracy가 0.04 증가하고 loss도 0.06증가 하였다.\n",
    "        \n",
    "- 5번째 시도 : n_dense의 수를 32 -> 64로 증가 시켜 보았다.\n",
    "        - 결과 test_accuracy: 0.550000011920929, test_loss: 1.751854419708252 \n",
    "        - accuracy가 0.04 증가했고 이번에는 loss가 1.7로 다시 줄어들었다.\n",
    "\n",
    "- 6번째 시도 : epoch을 30을 증가 시켜 보았다.\n",
    "        - 결과: test_accuracy: 0.5133333206176758, test_loss: 2.1954345703125 \n",
    "        - epoch은 적당량 이상 돌리면 오히려 점수가 낮아지는 것을 확인 했다.\n",
    "        \n",
    "- n_dense, epoch, 늘린 층을 삭제등 여러번 돌렸을때 test_accuracy: 47 ~ 55, 나오고 loss 같은 경우 1.7 ~ 2.4사이가 나왔다.\n",
    "\n",
    "\n",
    "- 늘린 층을 삭제후 n_channel_1,n_channel_2 숫자를 각가 32, 64로 변경하였고 n_dense을 64, epoch 20으로 돌렸다\n",
    "    - test_accuracy: 0.6366666555404663, test_loss: 1.0639227628707886는 결과가 나왔다. \n",
    "    \n",
    "    \n",
    "    \n",
    "- ```model.add(keras.layers.Dense(10, activation='softmax'))``` 이 부분을  3 -> 10으로 변경후 \n",
    "    - test_accuracy: 0.6566666960716248, test_loss: 1.1727834939956665 결과 출력\n",
    "    \n",
    "    \n",
    "- ```keras.layers.Dropout(0.25)```을 추가 하고 epoch 수를 늘렸지만 점수가 50~ 60점 사이의 점수가 나오고 loss 같은 <br>경우 1.2 ~ 2.2사이의 점수가 출력 되었다. \n",
    "\n",
    "\n",
    "- 이미지 사이즈를 (64,64) 변경했지만 정확도가 올라가지 안음 \n",
    "\n",
    "\n",
    "- 이후 많은 시도를 하였지만 결과가 좋지 못 했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc4074f",
   "metadata": {},
   "source": [
    "## 프로젝트를 통해 느낀점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b7189",
   "metadata": {},
   "source": [
    "이 프로젝트를 하면서 알고 있는 방법을 총 동원해 다양한 시도를 해보 았지만 최대 65퍼 이상을 올리지 못했고 같은 방법으로 돌려도 정확도와 loss가 차이가 발생했습니다. 그 이유를 생각해 보았을때 사진 데이터가 모두 다른 구조로 촬영된것과 배경이 있고 데이터의 양이 적은 것과 모델의 커스텀을 제대로 하지 못 하고 데이터 전처리 부분에서도 미숙하여 이러한 이유로 좋은 모델을 만들지 못한 것으로 판단됩니다. 이 프로젝트를 통해서 과적합을 막을 방법과 층을 늘리거나 복잡하게 만드는 방법등을 많이 시도해 보았고 그래서 이러한 부분을 많이 공부할 수 있었습니다. 이번 프로젝트에서 가장 부족한 했던 부분은 데이터 전처리라 생각되어 다음 프로젝트 부터는 데이터 전처리에 더 많은 시간을 투자하여 성능을 올려야 할것 같습니다. 또한 모델 설계 마지막 Dense에 10이 아닌 3이 들어가야 한다고 생각하지만 3보다 10 평균적으로 점수가 잘나와서 10을 사용하게 되었지만 이것에 대해서는 다음 프로젝트에서 더욱 신경써서 만들어 보아햐 할것 같습니다. 마지막으로 상황에 따라 층을 늘리거나 복잡하게 만드는 것이 꼭 좋은 모델을 만들 수 있는 것은 아닐수도 있다고 생각하게 되었습니다.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d504282a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
