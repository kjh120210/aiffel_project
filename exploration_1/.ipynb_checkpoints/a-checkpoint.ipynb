{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5d0a9b",
   "metadata": {},
   "source": [
    "# RockScisserPaper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf87c47",
   "metadata": {},
   "source": [
    "## 루브릭 평가\n",
    "\n",
    "1. 이미지 분류기 모델이 성공적으로 만들어졌는가?\n",
    "    - 트레이닝이 정상적으로 수행되었음\n",
    "2. 오버피팅을 극복하기 위한 적절한 시도가 있었는가?\n",
    "    - 데이터셋의 다양성, 정규화 등의 시도가 적절하였음\n",
    "3. 분류모델의 test accuracy가 기준 이상 높게 나왔는가?\n",
    "    - 60% 이상 도달하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cad90bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 라이브러리\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "571cafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기를 28X28로 변경하는 함수\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")\n",
    "    \n",
    "    print(len(images), \"images to be resized.\")\n",
    "    \n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \"images resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "cd91252b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1103 images to be resized.\n",
      "1103 images resized.\n",
      "1103 images to be resized.\n",
      "1103 images resized.\n",
      "1103 images to be resized.\n",
      "1103 images resized.\n"
     ]
    }
   ],
   "source": [
    "#가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") +\"/aiffel/aiffel_project/exploration_1/data/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "#바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") +\"/aiffel/aiffel_project/exploration_1/data/rock\"\n",
    "resize_images(image_dir_path)\n",
    "#보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") +\"/aiffel/aiffel_project/exploration_1/data/paper\"\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "45f53627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3309 입니다.\n",
      "x_train shape: (3309, 28, 28, 3)\n",
      "y_train shape: (3309,)\n"
     ]
    }
   ],
   "source": [
    "#훈련 데이터 함수\n",
    "def load_data(img_path, number_of_data=3309):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/aiffel_project/exploration_1/data\"\n",
    "\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2ce35723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images to be resized.\n",
      "100 images resized.\n",
      "100 images to be resized.\n",
      "100 images resized.\n",
      "100 images to be resized.\n",
      "100 images resized.\n",
      "테스트 데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n",
      "Before Reshape - x_test_norm shape: (300, 28, 28, 3)\n",
      "After Reshape - x_test_reshaped shape: (300, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 가져와 리사이즈 하기\n",
    "test_image_dir_path = os.getenv(\"HOME\") +\"/aiffel/aiffel_project/exploration_1/test/scissor\"\n",
    "resize_images(test_image_dir_path)\n",
    "test_image_dir_path = os.getenv(\"HOME\") +\"/aiffel/aiffel_project/exploration_1/test/rock\"\n",
    "resize_images(test_image_dir_path)\n",
    "test_image_dir_path = os.getenv(\"HOME\") +\"/aiffel/aiffel_project/exploration_1/test/paper\"\n",
    "resize_images(test_image_dir_path)\n",
    "\n",
    "# 테스트 데이터 함수\n",
    "def load_data_test(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트 데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "test_image_dir_path = os.getenv(\"HOME\") + \"/aiffel/aiffel_project/exploration_1/test\"\n",
    "\n",
    "(x_test, y_test)=load_data_test(test_image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n",
    "# 테스트 데이터 reshape 하기\n",
    "print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)\n",
    "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b91bd41",
   "metadata": {},
   "source": [
    "## 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7fede1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train_norm[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "63d5c3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Reshape - x_train_norm shape: (3309, 28, 28, 3)\n",
      "After Reshape - x_train_reshaped shape: (3309, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 reshape 하기\n",
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3)\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ef1b15",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b07dad37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_112 (Conv2D)          (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_106 (MaxPoolin (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_107 (MaxPoolin (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 122,051\n",
      "Trainable params: 122,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "#_channel_3=64\n",
    "n_dense=64\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "# model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "# model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "27300880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "104/104 [==============================] - 1s 4ms/step - loss: 1.0712 - accuracy: 0.4180\n",
      "Epoch 2/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.7762 - accuracy: 0.6685\n",
      "Epoch 3/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.8129\n",
      "Epoch 4/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8719\n",
      "Epoch 5/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.2537 - accuracy: 0.9193\n",
      "Epoch 6/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.1886 - accuracy: 0.9405\n",
      "Epoch 7/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9695\n",
      "Epoch 8/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0999 - accuracy: 0.9731\n",
      "Epoch 9/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9852\n",
      "Epoch 10/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9900\n",
      "Epoch 11/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.9943\n",
      "Epoch 12/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9961\n",
      "Epoch 13/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9967\n",
      "Epoch 14/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9997\n",
      "Epoch 15/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "테스트 결과\n",
      "10/10 - 0s - loss: 1.0639 - accuracy: 0.6367\n",
      "test_loss: 1.0639227628707886 \n",
      "test_accuracy: 0.6366666555404663\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)\n",
    "\n",
    "print('테스트 결과')\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a721356",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "### 사용한 데이터\n",
    "훈련 데이터 1103 * 3개  \n",
    "테스트 데이터 100 * 3개\n",
    "### 기록\n",
    "- 처음 정규화를 하지 않고 돌렸을때 test_accuracy가 0.03 test_loss가 10이상이 나왔다가 정규화를 하고 난 후에는 test_accuracy가 30퍼에 lose가 2점때가 나왔다. \n",
    "\n",
    "- 3번째 시도 : 층을 증가 시켜 보았다. \n",
    "        - 추가 했던 코드\n",
    "            - 결과 : test_accuracy: 0.47333332896232605, test_loss: 1.7697465419769287 \n",
    "            - 층을 늘리고 대략 17퍼 이상 올라가고 loss도 줄어들었다.\n",
    "```python\n",
    "n_channel_3=64\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "```\n",
    "- 4번째 시도 : epoch을 20으로 증가 시켜 보았다.\n",
    "        - 결과 test_accuracy : 0.5133333206176758, test_loss: 2.3954508304595947 \n",
    "        - accuracy가 0.04 증가하고 loss도 0.06증가 하였다.\n",
    "        \n",
    "- 5번째 시도 : n_dense의 수를 32 -> 64로 증가 시켜 보았다.\n",
    "        - 결과 test_accuracy: 0.550000011920929, test_loss: 1.751854419708252 \n",
    "        - accuracy가 0.04 증가했고 이번에는 loss가 1.7로 다시 줄어들었다.\n",
    "\n",
    "- 6번째 시도 : epoch을 30을 증가 시켜 보았다.\n",
    "        - 결과: test_accuracy: 0.5133333206176758, test_loss: 2.1954345703125 \n",
    "        - epoch은 적당량 이상 돌리면 오히려 점수가 낮아지는 것을 확인 했다.\n",
    "        \n",
    "- n_dense, epoch, 늘린 층을 삭제등 여러번 돌렸을때 test_accuracy: 47 ~ 55, 나오고 loss 같은 경우 1.7 ~ 2.4사이가 나왔다.\n",
    "\n",
    "- 늘린 층을 삭제후 n_channel_1,n_channel_2 숫자를 각가 32, 64로 변경하였고 n_dense을 64, epoch 20으로 돌렸다\n",
    "    - test_accuracy: 0.6366666555404663, test_accuracy: 0.6366666555404663는 결과가 나왔다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a153938",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
